{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.chdir('D:\\\\Fraud Analytics\\\\project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NY Property data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filling NA Zip Codes\n",
    "df['ZIP'].fillna(0,inplace=True)\n",
    "hh = df['ZIP'].tolist()\n",
    "for i in range(len(hh)):\n",
    "    if hh[i]==0:\n",
    "        hh[i]=hh[i-1]\n",
    "df['ZIP'] = hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillgroup(fillvalue,g1='ZIP',g2='TAXCLASS'):\n",
    "    df['ZT'] = df[g1].astype(int).astype(str)+''+df[g2].astype(str)\n",
    "## Use median groupby ZIP and TAXCLASS to fill the missing valuables\n",
    "    fullmedian_zt = df[df[fillvalue] != 0].groupby(['ZT'])[fillvalue].agg({'count':'count', 'median':'median'})\n",
    "    fullmedian_zt = fullmedian_zt[fullmedian_zt['count']>=10]\n",
    "## Merge by ZIPTAX\n",
    "    mer = df.merge(fullmedian_zt, how = 'left', left_on='ZT', right_index=True)\n",
    "## Fill in NA by ZIPTAX median\n",
    "    mer[fillvalue].replace(0,np.nan,inplace=True)\n",
    "    mer[fillvalue].fillna(mer['median'],inplace=True)\n",
    "    mer[fillvalue].fillna(0,inplace=True)\n",
    "    fullmedian_t = df[df[fillvalue] != 0].groupby([g2])[fillvalue].agg({'count2':'count', 'median2':'median'})\n",
    "    mer2 = mer.merge(fullmedian_t, how = 'left', left_on=g2, right_index=True)\n",
    "    mer2[fillvalue].replace(0,np.nan,inplace=True)\n",
    "    mer2[fillvalue].fillna(mer2['median2'],inplace=True)\n",
    "    df[fillvalue]=mer2[fillvalue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillgroup('FULLVAL',g1='ZIP',g2='TAXCLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillgroup('AVTOT',g1='ZIP',g2='TAXCLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillgroup('AVLAND',g1='ZIP',g2='TAXCLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillgroup('LTFRONT',g1='ZIP',g2='TAXCLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillgroup('LTDEPTH',g1='ZIP',g2='TAXCLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillgroup('BLDFRONT',g1='ZIP',g2='TAXCLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillgroup('BLDDEPTH',g1='ZIP',g2='TAXCLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillgroup('STORIES',g1='ZIP',g2='TAXCLASS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building variables\n",
    "\n",
    "Use the combination of the previous variables to build variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df[['RECORD','FULLVAL','AVLAND', 'AVTOT', 'LTFRONT', 'LTDEPTH', 'BLDFRONT', 'BLDDEPTH', 'ZIP', 'STORIES','B','TAXCLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['S1'] = final_df['LTFRONT'] *final_df['LTDEPTH']\n",
    "#Area variables by multiplying the Loftfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['S2'] = final_df['BLDFRONT'] *final_df['BLDDEPTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['S3'] = final_df['S2'] *final_df['STORIES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['r1'] = final_df['FULLVAL'] /final_df['S1']\n",
    "final_df['r2'] = final_df['FULLVAL'] /final_df['S2']\n",
    "final_df['r3'] = final_df['FULLVAL'] /final_df['S3']\n",
    "final_df['r4'] = final_df['AVLAND'] /final_df['S1']\n",
    "final_df['r5'] = final_df['AVLAND'] /final_df['S2']\n",
    "final_df['r6'] = final_df['AVLAND'] /final_df['S3']\n",
    "final_df['r7'] = final_df['AVTOT'] /final_df['S1']\n",
    "final_df['r8'] = final_df['AVTOT'] /final_df['S2']\n",
    "final_df['r9'] = final_df['AVTOT'] /final_df['S3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in final_df['ZIP'].astype(int).astype(str):\n",
    "    result.append(i[:3])\n",
    "final_df['ZIP3'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = final_df.groupby('ZIP')[['r1','r2','r3','r4','r5','r6','r7','r8','r9']].mean()\n",
    "g1.columns = ['r1g1','r2g1','r3g1','r4g1','r5g1','r6g1','r7g1','r8g1','r9g1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = final_df.groupby('ZIP3')[['r1','r2','r3','r4','r5','r6','r7','r8','r9']].mean()\n",
    "g2.columns = ['r1g2','r2g2','r3g2','r4g2','r5g2','r6g2','r7g2','r8g2','r9g2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3 = final_df.groupby('TAXCLASS')[['r1','r2','r3','r4','r5','r6','r7','r8','r9']].mean()\n",
    "g3.columns = ['r1g3','r2g3','r3g3','r4g3','r5g3','r6g3','r7g3','r8g3','r9g3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4 = final_df.groupby('B')[['r1','r2','r3','r4','r5','r6','r7','r8','r9']].mean()\n",
    "g4.columns = ['r1g4','r2g4','r3g4','r4g4','r5g4','r6g4','r7g4','r8g4','r9g4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.merge(g1,how='left',right_index=True,left_on='ZIP')\n",
    "final_df=final_df.merge(g2,how='left',right_index=True,left_on='ZIP3')\n",
    "final_df=final_df.merge(g3,how='left',right_index=True,left_on='TAXCLASS')\n",
    "final_df=final_df.merge(g4,how='left',right_index=True,left_on='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['r1g1']=final_df['r1']/final_df['r1g1']\n",
    "final_df['r2g1']=final_df['r2']/final_df['r2g1']\n",
    "final_df['r3g1']=final_df['r3']/final_df['r3g1']\n",
    "final_df['r4g1']=final_df['r4']/final_df['r4g1']\n",
    "final_df['r5g1']=final_df['r5']/final_df['r5g1']\n",
    "final_df['r6g1']=final_df['r6']/final_df['r6g1']\n",
    "final_df['r7g1']=final_df['r7']/final_df['r7g1']\n",
    "final_df['r8g1']=final_df['r8']/final_df['r8g1']\n",
    "final_df['r9g1']=final_df['r9']/final_df['r9g1']\n",
    "final_df['r1g2']=final_df['r1']/final_df['r1g2']\n",
    "final_df['r2g2']=final_df['r2']/final_df['r2g2']\n",
    "final_df['r3g2']=final_df['r3']/final_df['r3g2']\n",
    "final_df['r4g2']=final_df['r4']/final_df['r4g2']\n",
    "final_df['r5g2']=final_df['r5']/final_df['r5g2']\n",
    "final_df['r6g2']=final_df['r6']/final_df['r6g2']\n",
    "final_df['r7g2']=final_df['r7']/final_df['r7g2']\n",
    "final_df['r8g2']=final_df['r8']/final_df['r8g2']\n",
    "final_df['r9g2']=final_df['r9']/final_df['r9g2']\n",
    "final_df['r1g3']=final_df['r1']/final_df['r1g3']\n",
    "final_df['r2g3']=final_df['r2']/final_df['r2g3']\n",
    "final_df['r3g3']=final_df['r3']/final_df['r3g3']\n",
    "final_df['r4g3']=final_df['r4']/final_df['r4g3']\n",
    "final_df['r5g3']=final_df['r5']/final_df['r5g3']\n",
    "final_df['r6g3']=final_df['r6']/final_df['r6g3']\n",
    "final_df['r7g3']=final_df['r7']/final_df['r7g3']\n",
    "final_df['r8g3']=final_df['r8']/final_df['r8g3']\n",
    "final_df['r9g3']=final_df['r9']/final_df['r9g3']\n",
    "final_df['r1g4']=final_df['r1']/final_df['r1g4']\n",
    "final_df['r2g4']=final_df['r2']/final_df['r2g4']\n",
    "final_df['r3g4']=final_df['r3']/final_df['r3g4']\n",
    "final_df['r4g4']=final_df['r4']/final_df['r4g4']\n",
    "final_df['r5g4']=final_df['r5']/final_df['r5g4']\n",
    "final_df['r6g4']=final_df['r6']/final_df['r6g4']\n",
    "final_df['r7g4']=final_df['r7']/final_df['r7g4']\n",
    "final_df['r8g4']=final_df['r8']/final_df['r8g4']\n",
    "final_df['r9g4']=final_df['r9']/final_df['r9g4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.5712967723201262e-16, 0.9999999999999998)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final_df['r1g1']\n",
    "from sklearn.preprocessing import scale\n",
    "r1g1_scale = scale(X)\n",
    "np.mean(r1g1_scale), np.std(r1g1_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_df.columns[15:24].tolist()+final_df.columns[25:].tolist():\n",
    "    final_df[i] = scale(final_df[i])\n",
    "    #np.mean(final_df[i]), np.std(final_df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = final_df[final_df.columns[15:24].tolist()+final_df.columns[25:].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "pca.fit(pdf)\n",
    "pca_df = pca.transform(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df=pd.DataFrame(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-scale after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pca_df.columns:\n",
    "    pca_df[i] = scale(pca_df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df['8']=pca_df.abs().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankpca=pca_df.sort_values(by='8',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankpca['9']=range(1,1070995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rankpca[['9']]\n",
    "score.columns=['score1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "pca.fit(pdf)\n",
    "pca_df = pca.transform(pdf)\n",
    "pca_df=pd.DataFrame(pca_df)\n",
    "for i in pca_df.columns:\n",
    "    pca_df[i] = scale(pca_df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pylab import rcParams\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 128\n",
    "input_dim = pca_df.shape[1] #num of columns, 8\n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) #i.e. 7\n",
    "learning_rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gordo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gordo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1070994 samples, validate on 1070994 samples\n",
      "Epoch 1/10\n",
      "1070994/1070994 [==============================] - 24s 23us/step - loss: 0.9696 - acc: 0.8021 - val_loss: 0.9556 - val_acc: 0.8412\n",
      "Epoch 2/10\n",
      "1070994/1070994 [==============================] - 22s 21us/step - loss: 0.9470 - acc: 0.8253 - val_loss: 0.9385 - val_acc: 0.8203\n",
      "Epoch 3/10\n",
      "1070994/1070994 [==============================] - 22s 20us/step - loss: 0.9327 - acc: 0.8188 - val_loss: 0.9264 - val_acc: 0.8413\n",
      "Epoch 4/10\n",
      "1070994/1070994 [==============================] - 22s 21us/step - loss: 0.9216 - acc: 0.8318 - val_loss: 0.9164 - val_acc: 0.6866\n",
      "Epoch 5/10\n",
      "1070994/1070994 [==============================] - 22s 20us/step - loss: 0.9133 - acc: 0.8340 - val_loss: 0.9082 - val_acc: 0.8236\n",
      "Epoch 6/10\n",
      "1070994/1070994 [==============================] - 22s 21us/step - loss: 0.9038 - acc: 0.8376 - val_loss: 0.8992 - val_acc: 0.8445\n",
      "Epoch 7/10\n",
      "1070994/1070994 [==============================] - 22s 21us/step - loss: 0.8968 - acc: 0.8339 - val_loss: 0.8927 - val_acc: 0.8003\n",
      "Epoch 8/10\n",
      "1070994/1070994 [==============================] - 25s 23us/step - loss: 0.8901 - acc: 0.8188 - val_loss: 0.8874 - val_acc: 0.8440\n",
      "Epoch 9/10\n",
      "1070994/1070994 [==============================] - 26s 24us/step - loss: 0.8851 - acc: 0.8185 - val_loss: 0.8834 - val_acc: 0.8182\n",
      "Epoch 10/10\n",
      "1070994/1070994 [==============================] - 26s 24us/step - loss: 0.8798 - acc: 0.7640 - val_loss: 0.8795 - val_acc: 0.8131\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(pca_df, pca_df,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(pca_df, pca_df),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('autoencoder_fraud.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=autoencoder.predict(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070994, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=prediction-pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff['8']=diff.abs().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankdiff=diff.sort_values(by='8',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankdiff['9']=range(1,1070995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "score[2] = rankdiff[['9']]\n",
    "score.columns=['score1','score2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['total']=score['score1']+score['score2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632815</th>\n",
       "      <td>1070994</td>\n",
       "      <td>1070994</td>\n",
       "      <td>2141988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565391</th>\n",
       "      <td>1070993</td>\n",
       "      <td>1070993</td>\n",
       "      <td>2141986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067359</th>\n",
       "      <td>1070992</td>\n",
       "      <td>1070992</td>\n",
       "      <td>2141984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917941</th>\n",
       "      <td>1070991</td>\n",
       "      <td>1070991</td>\n",
       "      <td>2141982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585117</th>\n",
       "      <td>1070990</td>\n",
       "      <td>1070990</td>\n",
       "      <td>2141980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85885</th>\n",
       "      <td>1070989</td>\n",
       "      <td>1070988</td>\n",
       "      <td>2141977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585438</th>\n",
       "      <td>1070988</td>\n",
       "      <td>1070989</td>\n",
       "      <td>2141977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565397</th>\n",
       "      <td>1070987</td>\n",
       "      <td>1070987</td>\n",
       "      <td>2141974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585119</th>\n",
       "      <td>1070984</td>\n",
       "      <td>1070986</td>\n",
       "      <td>2141970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556608</th>\n",
       "      <td>1070985</td>\n",
       "      <td>1070985</td>\n",
       "      <td>2141970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920627</th>\n",
       "      <td>1070986</td>\n",
       "      <td>1070984</td>\n",
       "      <td>2141970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690832</th>\n",
       "      <td>1070983</td>\n",
       "      <td>1070982</td>\n",
       "      <td>2141965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750815</th>\n",
       "      <td>1070982</td>\n",
       "      <td>1070981</td>\n",
       "      <td>2141963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935157</th>\n",
       "      <td>1070980</td>\n",
       "      <td>1070983</td>\n",
       "      <td>2141963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776305</th>\n",
       "      <td>1070981</td>\n",
       "      <td>1070980</td>\n",
       "      <td>2141961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691878</th>\n",
       "      <td>1070978</td>\n",
       "      <td>1070979</td>\n",
       "      <td>2141957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067000</th>\n",
       "      <td>1070979</td>\n",
       "      <td>1070977</td>\n",
       "      <td>2141956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67128</th>\n",
       "      <td>1070977</td>\n",
       "      <td>1070978</td>\n",
       "      <td>2141955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770593</th>\n",
       "      <td>1070976</td>\n",
       "      <td>1070976</td>\n",
       "      <td>2141952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794104</th>\n",
       "      <td>1070975</td>\n",
       "      <td>1070974</td>\n",
       "      <td>2141949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score1   score2    total\n",
       "632815   1070994  1070994  2141988\n",
       "565391   1070993  1070993  2141986\n",
       "1067359  1070992  1070992  2141984\n",
       "917941   1070991  1070991  2141982\n",
       "585117   1070990  1070990  2141980\n",
       "85885    1070989  1070988  2141977\n",
       "585438   1070988  1070989  2141977\n",
       "565397   1070987  1070987  2141974\n",
       "585119   1070984  1070986  2141970\n",
       "556608   1070985  1070985  2141970\n",
       "920627   1070986  1070984  2141970\n",
       "690832   1070983  1070982  2141965\n",
       "750815   1070982  1070981  2141963\n",
       "935157   1070980  1070983  2141963\n",
       "776305   1070981  1070980  2141961\n",
       "691878   1070978  1070979  2141957\n",
       "1067000  1070979  1070977  2141956\n",
       "67128    1070977  1070978  2141955\n",
       "770593   1070976  1070976  2141952\n",
       "794104   1070975  1070974  2141949"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By ranking the total score, we consider the highest 20 records as abnormal records\n",
    "score.sort_values(by='total',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.to_csv('score.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
