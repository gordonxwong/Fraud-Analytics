{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.read_csv('NY Property data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NY Property data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filling NA Zip Codes\n",
    "df['ZIP'].fillna(0,inplace=True)\n",
    "hh = df['ZIP'].tolist()\n",
    "for i in range(len(hh)):\n",
    "    if hh[i]==0:\n",
    "        hh[i]=hh[i-1]\n",
    "df['ZIP'] = hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZT'] = df['ZIP'].astype(int).astype(str)+''+df['TAXCLASS'].astype(str)\n",
    "## Fullval median groupby ZIP and TAXCLASS\n",
    "fullmedian_zt = df[df['FULLVAL'] != 0].groupby(['ZT'])['FULLVAL'].agg({'count':'count', 'median':'median'})\n",
    "fullmedian_zt = fullmedian_zt[fullmedian_zt['count']>=10]\n",
    "## Merge by ZIPTAX\n",
    "mer = df.merge(fullmedian_zt, how = 'left', left_on='ZT', right_index=True)\n",
    "## Fill in NA by ZIPTAX median\n",
    "mer['FULLVAL'].replace(0,np.nan,inplace=True)\n",
    "mer['FULLVAL'].fillna(mer['median'],inplace=True)\n",
    "mer['FULLVAL'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullmedian_t = df[df['FULLVAL'] != 0].groupby(['TAXCLASS'])['FULLVAL'].agg({'count2':'count', 'median2':'median'})\n",
    "mer2 = mer.merge(fullmedian_t, how = 'left', left_on='TAXCLASS', right_index=True)\n",
    "mer2['FULLVAL'].replace(0,np.nan,inplace=True)\n",
    "mer2['FULLVAL'].fillna(mer2['median2'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FULLVAL']=mer2['FULLVAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZT'] = df['ZIP'].astype(int).astype(str)+''+df['TAXCLASS'].astype(str)\n",
    "## AVTOT median groupby ZIP and TAXCLASS\n",
    "fullmedian_zt = df[df['AVTOT'] != 0].groupby(['ZT'])['AVTOT'].agg({'count':'count', 'median':'median'})\n",
    "fullmedian_zt = fullmedian_zt[fullmedian_zt['count']>=10]\n",
    "## Merge by ZIPTAX\n",
    "mer = df.merge(fullmedian_zt, how = 'left', left_on='ZT', right_index=True)\n",
    "## Fill in NA by ZIPTAX median\n",
    "mer['AVTOT'].replace(0,np.nan,inplace=True)\n",
    "mer['AVTOT'].fillna(mer['median'],inplace=True)\n",
    "mer['AVTOT'].fillna(0,inplace=True)\n",
    "fullmedian_t = df[df['AVTOT'] != 0].groupby(['TAXCLASS'])['AVTOT'].agg({'count2':'count', 'median2':'median'})\n",
    "mer2 = mer.merge(fullmedian_t, how = 'left', left_on='TAXCLASS', right_index=True)\n",
    "mer2['AVTOT'].replace(0,np.nan,inplace=True)\n",
    "mer2['AVTOT'].fillna(mer2['median2'],inplace=True)\n",
    "df['AVTOT']=mer2['AVTOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZT'] = df['ZIP'].astype(int).astype(str)+''+df['TAXCLASS'].astype(str)\n",
    "## AVLAND median groupby ZIP and TAXCLASS\n",
    "fullmedian_zt = df[df['AVLAND'] != 0].groupby(['ZT'])['AVLAND'].agg({'count':'count', 'median':'median'})\n",
    "fullmedian_zt = fullmedian_zt[fullmedian_zt['count']>=10]\n",
    "## Merge by ZIPTAX\n",
    "mer = df.merge(fullmedian_zt, how = 'left', left_on='ZT', right_index=True)\n",
    "## Fill in NA by ZIPTAX median\n",
    "mer['AVLAND'].replace(0,np.nan,inplace=True)\n",
    "mer['AVLAND'].fillna(mer['median'],inplace=True)\n",
    "mer['AVLAND'].fillna(0,inplace=True)\n",
    "fullmedian_t = df[df['AVLAND'] != 0].groupby(['TAXCLASS'])['AVLAND'].agg({'count2':'count', 'median2':'median'})\n",
    "mer2 = mer.merge(fullmedian_t, how = 'left', left_on='TAXCLASS', right_index=True)\n",
    "mer2['AVLAND'].replace(0,np.nan,inplace=True)\n",
    "mer2['AVLAND'].fillna(mer2['median2'],inplace=True)\n",
    "df['AVLAND']=mer2['AVLAND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZT'] = df['ZIP'].astype(int).astype(str)+''+df['TAXCLASS'].astype(str)\n",
    "## LTFRONT median groupby ZIP and TAXCLASS\n",
    "fullmedian_zt = df[df['LTFRONT'] != 0].groupby(['ZT'])['LTFRONT'].agg({'count':'count', 'median':'median'})\n",
    "fullmedian_zt = fullmedian_zt[fullmedian_zt['count']>=10]\n",
    "## Merge by ZIPTAX\n",
    "mer = df.merge(fullmedian_zt, how = 'left', left_on='ZT', right_index=True)\n",
    "## Fill in NA by ZIPTAX median\n",
    "mer['LTFRONT'].replace(0,np.nan,inplace=True)\n",
    "mer['LTFRONT'].fillna(mer['median'],inplace=True)\n",
    "mer['LTFRONT'].fillna(0,inplace=True)\n",
    "fullmedian_t = df[df['LTFRONT'] != 0].groupby(['TAXCLASS'])['LTFRONT'].agg({'count2':'count', 'median2':'median'})\n",
    "mer2 = mer.merge(fullmedian_t, how = 'left', left_on='TAXCLASS', right_index=True)\n",
    "mer2['LTFRONT'].replace(0,np.nan,inplace=True)\n",
    "mer2['LTFRONT'].fillna(mer2['median2'],inplace=True)\n",
    "df['LTFRONT']=mer2['LTFRONT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZT'] = df['ZIP'].astype(int).astype(str)+''+df['TAXCLASS'].astype(str)\n",
    "## LTDEPTH median groupby ZIP and TAXCLASS\n",
    "fullmedian_zt = df[df['LTDEPTH'] != 0].groupby(['ZT'])['LTDEPTH'].agg({'count':'count', 'median':'median'})\n",
    "fullmedian_zt = fullmedian_zt[fullmedian_zt['count']>=10]\n",
    "## Merge by ZIPTAX\n",
    "mer = df.merge(fullmedian_zt, how = 'left', left_on='ZT', right_index=True)\n",
    "## Fill in NA by ZIPTAX median\n",
    "mer['LTDEPTH'].replace(0,np.nan,inplace=True)\n",
    "mer['LTDEPTH'].fillna(mer['median'],inplace=True)\n",
    "mer['LTDEPTH'].fillna(0,inplace=True)\n",
    "fullmedian_t = df[df['LTDEPTH'] != 0].groupby(['TAXCLASS'])['LTDEPTH'].agg({'count2':'count', 'median2':'median'})\n",
    "mer2 = mer.merge(fullmedian_t, how = 'left', left_on='TAXCLASS', right_index=True)\n",
    "mer2['LTDEPTH'].replace(0,np.nan,inplace=True)\n",
    "mer2['LTDEPTH'].fillna(mer2['median2'],inplace=True)\n",
    "df['LTDEPTH']=mer2['LTDEPTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZT'] = df['ZIP'].astype(int).astype(str)+''+df['TAXCLASS'].astype(str)\n",
    "## BLDFRONT median groupby ZIP and TAXCLASS\n",
    "fullmedian_zt = df[df['BLDFRONT'] != 0].groupby(['ZT'])['BLDFRONT'].agg({'count':'count', 'median':'median'})\n",
    "fullmedian_zt = fullmedian_zt[fullmedian_zt['count']>=10]\n",
    "## Merge by ZIPTAX\n",
    "mer = df.merge(fullmedian_zt, how = 'left', left_on='ZT', right_index=True)\n",
    "## Fill in NA by ZIPTAX median\n",
    "mer['BLDFRONT'].replace(0,np.nan,inplace=True)\n",
    "mer['BLDFRONT'].fillna(mer['median'],inplace=True)\n",
    "mer['BLDFRONT'].fillna(0,inplace=True)\n",
    "fullmedian_t = df[df['BLDFRONT'] != 0].groupby(['TAXCLASS'])['BLDFRONT'].agg({'count2':'count', 'median2':'median'})\n",
    "mer2 = mer.merge(fullmedian_t, how = 'left', left_on='TAXCLASS', right_index=True)\n",
    "mer2['BLDFRONT'].replace(0,np.nan,inplace=True)\n",
    "mer2['BLDFRONT'].fillna(mer2['median2'],inplace=True)\n",
    "df['BLDFRONT']=mer2['BLDFRONT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZT'] = df['ZIP'].astype(int).astype(str)+''+df['TAXCLASS'].astype(str)\n",
    "## BLDDEPTH median groupby ZIP and TAXCLASS\n",
    "fullmedian_zt = df[df['BLDDEPTH'] != 0].groupby(['ZT'])['BLDDEPTH'].agg({'count':'count', 'median':'median'})\n",
    "fullmedian_zt = fullmedian_zt[fullmedian_zt['count']>=10]\n",
    "## Merge by ZIPTAX\n",
    "mer = df.merge(fullmedian_zt, how = 'left', left_on='ZT', right_index=True)\n",
    "## Fill in NA by ZIPTAX median\n",
    "mer['BLDDEPTH'].replace(0,np.nan,inplace=True)\n",
    "mer['BLDDEPTH'].fillna(mer['median'],inplace=True)\n",
    "mer['BLDDEPTH'].fillna(0,inplace=True)\n",
    "fullmedian_t = df[df['BLDDEPTH'] != 0].groupby(['TAXCLASS'])['BLDDEPTH'].agg({'count2':'count', 'median2':'median'})\n",
    "mer2 = mer.merge(fullmedian_t, how = 'left', left_on='TAXCLASS', right_index=True)\n",
    "mer2['BLDDEPTH'].replace(0,np.nan,inplace=True)\n",
    "mer2['BLDDEPTH'].fillna(mer2['median2'],inplace=True)\n",
    "df['BLDDEPTH']=mer2['BLDDEPTH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZT'] = df['ZIP'].astype(int).astype(str)+''+df['TAXCLASS'].astype(str)\n",
    "## STORIES median groupby ZIP and TAXCLASS\n",
    "df['STORIES'].replace(np.nan,0,inplace=True)\n",
    "fullmedian_zt = df[df['STORIES'] != 0].groupby(['ZT'])['STORIES'].agg({'count':'count', 'median':'median'})\n",
    "fullmedian_zt = fullmedian_zt[fullmedian_zt['count']>=10]\n",
    "## Merge by ZIPTAX\n",
    "mer = df.merge(fullmedian_zt, how = 'left', left_on='ZT', right_index=True)\n",
    "## Fill in NA by ZIPTAX median\n",
    "mer['STORIES'].replace(0,np.nan,inplace=True)\n",
    "mer['STORIES'].fillna(mer['median'],inplace=True)\n",
    "mer['STORIES'].fillna(0,inplace=True)\n",
    "fullmedian_t = df[df['STORIES'] != 0].groupby(['TAXCLASS'])['STORIES'].agg({'count2':'count', 'median2':'median'})\n",
    "mer2 = mer.merge(fullmedian_t, how = 'left', left_on='TAXCLASS', right_index=True)\n",
    "mer2['STORIES'].replace(0,np.nan,inplace=True)\n",
    "mer2['STORIES'].fillna(mer2['median2'],inplace=True)\n",
    "df['STORIES']=mer2['STORIES']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df[['RECORD','FULLVAL','AVLAND', 'AVTOT', 'LTFRONT', 'LTDEPTH', 'BLDFRONT', 'BLDDEPTH', 'ZIP', 'STORIES','B','TAXCLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['S1'] = final_df['LTFRONT'] *final_df['LTDEPTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['S2'] = final_df['BLDFRONT'] *final_df['BLDDEPTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['S3'] = final_df['S2'] *final_df['STORIES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['r1'] = final_df['FULLVAL'] /final_df['S1']\n",
    "final_df['r2'] = final_df['FULLVAL'] /final_df['S2']\n",
    "final_df['r3'] = final_df['FULLVAL'] /final_df['S3']\n",
    "final_df['r4'] = final_df['AVLAND'] /final_df['S1']\n",
    "final_df['r5'] = final_df['AVLAND'] /final_df['S2']\n",
    "final_df['r6'] = final_df['AVLAND'] /final_df['S3']\n",
    "final_df['r7'] = final_df['AVTOT'] /final_df['S1']\n",
    "final_df['r8'] = final_df['AVTOT'] /final_df['S2']\n",
    "final_df['r9'] = final_df['AVTOT'] /final_df['S3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in final_df['ZIP'].astype(int).astype(str):\n",
    "    result.append(i[:3])\n",
    "final_df['ZIP3'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = final_df.groupby('ZIP')[['r1','r2','r3','r4','r5','r6','r7','r8','r9']].mean()\n",
    "g1.columns = ['r1g1','r2g1','r3g1','r4g1','r5g1','r6g1','r7g1','r8g1','r9g1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = final_df.groupby('ZIP3')[['r1','r2','r3','r4','r5','r6','r7','r8','r9']].mean()\n",
    "g2.columns = ['r1g2','r2g2','r3g2','r4g2','r5g2','r6g2','r7g2','r8g2','r9g2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3 = final_df.groupby('TAXCLASS')[['r1','r2','r3','r4','r5','r6','r7','r8','r9']].mean()\n",
    "g3.columns = ['r1g3','r2g3','r3g3','r4g3','r5g3','r6g3','r7g3','r8g3','r9g3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "g4 = final_df.groupby('B')[['r1','r2','r3','r4','r5','r6','r7','r8','r9']].mean()\n",
    "g4.columns = ['r1g4','r2g4','r3g4','r4g4','r5g4','r6g4','r7g4','r8g4','r9g4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=final_df.merge(g1,how='left',right_index=True,left_on='ZIP')\n",
    "final_df=final_df.merge(g2,how='left',right_index=True,left_on='ZIP3')\n",
    "final_df=final_df.merge(g3,how='left',right_index=True,left_on='TAXCLASS')\n",
    "final_df=final_df.merge(g4,how='left',right_index=True,left_on='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['r1g1']=final_df['r1']/final_df['r1g1']\n",
    "final_df['r2g1']=final_df['r2']/final_df['r2g1']\n",
    "final_df['r3g1']=final_df['r3']/final_df['r3g1']\n",
    "final_df['r4g1']=final_df['r4']/final_df['r4g1']\n",
    "final_df['r5g1']=final_df['r5']/final_df['r5g1']\n",
    "final_df['r6g1']=final_df['r6']/final_df['r6g1']\n",
    "final_df['r7g1']=final_df['r7']/final_df['r7g1']\n",
    "final_df['r8g1']=final_df['r8']/final_df['r8g1']\n",
    "final_df['r9g1']=final_df['r9']/final_df['r9g1']\n",
    "final_df['r1g2']=final_df['r1']/final_df['r1g2']\n",
    "final_df['r2g2']=final_df['r2']/final_df['r2g2']\n",
    "final_df['r3g2']=final_df['r3']/final_df['r3g2']\n",
    "final_df['r4g2']=final_df['r4']/final_df['r4g2']\n",
    "final_df['r5g2']=final_df['r5']/final_df['r5g2']\n",
    "final_df['r6g2']=final_df['r6']/final_df['r6g2']\n",
    "final_df['r7g2']=final_df['r7']/final_df['r7g2']\n",
    "final_df['r8g2']=final_df['r8']/final_df['r8g2']\n",
    "final_df['r9g2']=final_df['r9']/final_df['r9g2']\n",
    "final_df['r1g3']=final_df['r1']/final_df['r1g3']\n",
    "final_df['r2g3']=final_df['r2']/final_df['r2g3']\n",
    "final_df['r3g3']=final_df['r3']/final_df['r3g3']\n",
    "final_df['r4g3']=final_df['r4']/final_df['r4g3']\n",
    "final_df['r5g3']=final_df['r5']/final_df['r5g3']\n",
    "final_df['r6g3']=final_df['r6']/final_df['r6g3']\n",
    "final_df['r7g3']=final_df['r7']/final_df['r7g3']\n",
    "final_df['r8g3']=final_df['r8']/final_df['r8g3']\n",
    "final_df['r9g3']=final_df['r9']/final_df['r9g3']\n",
    "final_df['r1g4']=final_df['r1']/final_df['r1g4']\n",
    "final_df['r2g4']=final_df['r2']/final_df['r2g4']\n",
    "final_df['r3g4']=final_df['r3']/final_df['r3g4']\n",
    "final_df['r4g4']=final_df['r4']/final_df['r4g4']\n",
    "final_df['r5g4']=final_df['r5']/final_df['r5g4']\n",
    "final_df['r6g4']=final_df['r6']/final_df['r6g4']\n",
    "final_df['r7g4']=final_df['r7']/final_df['r7g4']\n",
    "final_df['r8g4']=final_df['r8']/final_df['r8g4']\n",
    "final_df['r9g4']=final_df['r9']/final_df['r9g4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.5391861644074873e-18, 1.0)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final_df['r1g1']\n",
    "from sklearn.preprocessing import scale\n",
    "r1g1_scale = scale(X)\n",
    "np.mean(r1g1_scale), np.std(r1g1_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_df.columns[15:24].tolist()+final_df.columns[25:].tolist():\n",
    "    final_df[i] = scale(final_df[i])\n",
    "    #np.mean(final_df[i]), np.std(final_df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = final_df[final_df.columns[15:24].tolist()+final_df.columns[25:].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "pca.fit(pdf)\n",
    "pca_df = pca.transform(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df=pd.DataFrame(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-scale after PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pca_df.columns:\n",
    "    pca_df[i] = scale(pca_df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df['8']=pca_df.abs().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankpca=pca_df.sort_values(by='8',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankpca['9']=range(1,1070995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rankpca[['9']]\n",
    "score.columns=['score1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "pca.fit(pdf)\n",
    "pca_df = pca.transform(pdf)\n",
    "pca_df=pd.DataFrame(pca_df)\n",
    "for i in pca_df.columns:\n",
    "    pca_df[i] = scale(pca_df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pylab import rcParams\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 128\n",
    "input_dim = pca_df.shape[1] #num of columns, 8\n",
    "encoding_dim = 14\n",
    "hidden_dim = int(encoding_dim / 2) #i.e. 7\n",
    "learning_rate = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
    "encoder = Dense(hidden_dim, activation=\"relu\")(encoder)\n",
    "decoder = Dense(hidden_dim, activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1070994 samples, validate on 1070994 samples\n",
      "Epoch 1/10\n",
      "1070994/1070994 [==============================] - 16s 15us/step - loss: 0.9754 - acc: 0.7772 - val_loss: 0.9674 - val_acc: 0.8194\n",
      "Epoch 2/10\n",
      "1070994/1070994 [==============================] - 15s 14us/step - loss: 0.9622 - acc: 0.8512 - val_loss: 0.9518 - val_acc: 0.8741\n",
      "Epoch 3/10\n",
      "1070994/1070994 [==============================] - 15s 14us/step - loss: 0.9443 - acc: 0.8761 - val_loss: 0.9353 - val_acc: 0.8885\n",
      "Epoch 4/10\n",
      "1070994/1070994 [==============================] - 15s 14us/step - loss: 0.9297 - acc: 0.8816 - val_loss: 0.9230 - val_acc: 0.8865\n",
      "Epoch 5/10\n",
      "1070994/1070994 [==============================] - 15s 14us/step - loss: 0.9193 - acc: 0.8784 - val_loss: 0.9146 - val_acc: 0.8167\n",
      "Epoch 6/10\n",
      "1070994/1070994 [==============================] - 15s 14us/step - loss: 0.9097 - acc: 0.8655 - val_loss: 0.9052 - val_acc: 0.8752\n",
      "Epoch 7/10\n",
      "1070994/1070994 [==============================] - 15s 14us/step - loss: 0.9019 - acc: 0.8585 - val_loss: 0.8979 - val_acc: 0.8766\n",
      "Epoch 8/10\n",
      "1070994/1070994 [==============================] - 15s 14us/step - loss: 0.8952 - acc: 0.8676 - val_loss: 0.8923 - val_acc: 0.8662\n",
      "Epoch 9/10\n",
      "1070994/1070994 [==============================] - 16s 15us/step - loss: 0.8878 - acc: 0.8617 - val_loss: 0.8848 - val_acc: 0.8600\n",
      "Epoch 10/10\n",
      "1070994/1070994 [==============================] - 16s 15us/step - loss: 0.8836 - acc: 0.8548 - val_loss: 0.8812 - val_acc: 0.8511\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(metrics=['accuracy'],\n",
    "                    loss='mean_squared_error',\n",
    "                    optimizer='adam')\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_fraud.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "history = autoencoder.fit(pca_df, pca_df,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(pca_df, pca_df),\n",
    "                    verbose=1,\n",
    "                    callbacks=[cp, tb]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('autoencoder_fraud.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=autoencoder.predict(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070994, 8)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=prediction-pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff['8']=diff.abs().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankdiff=diff.sort_values(by='8',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankdiff['9']=range(1,1070995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "score[2] = rankdiff[['9']]\n",
    "score.columns=['score1','score2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "score['total']=score['score1']+score['score2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632815</th>\n",
       "      <td>1070994</td>\n",
       "      <td>1070994</td>\n",
       "      <td>2141988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565391</th>\n",
       "      <td>1070993</td>\n",
       "      <td>1070993</td>\n",
       "      <td>2141986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067359</th>\n",
       "      <td>1070992</td>\n",
       "      <td>1070992</td>\n",
       "      <td>2141984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917941</th>\n",
       "      <td>1070991</td>\n",
       "      <td>1070991</td>\n",
       "      <td>2141982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585117</th>\n",
       "      <td>1070990</td>\n",
       "      <td>1070990</td>\n",
       "      <td>2141980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85885</th>\n",
       "      <td>1070989</td>\n",
       "      <td>1070989</td>\n",
       "      <td>2141978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585438</th>\n",
       "      <td>1070988</td>\n",
       "      <td>1070988</td>\n",
       "      <td>2141976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565397</th>\n",
       "      <td>1070987</td>\n",
       "      <td>1070987</td>\n",
       "      <td>2141974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920627</th>\n",
       "      <td>1070986</td>\n",
       "      <td>1070986</td>\n",
       "      <td>2141972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556608</th>\n",
       "      <td>1070985</td>\n",
       "      <td>1070985</td>\n",
       "      <td>2141970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585119</th>\n",
       "      <td>1070984</td>\n",
       "      <td>1070984</td>\n",
       "      <td>2141968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690832</th>\n",
       "      <td>1070983</td>\n",
       "      <td>1070983</td>\n",
       "      <td>2141966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750815</th>\n",
       "      <td>1070982</td>\n",
       "      <td>1070982</td>\n",
       "      <td>2141964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776305</th>\n",
       "      <td>1070981</td>\n",
       "      <td>1070981</td>\n",
       "      <td>2141962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935157</th>\n",
       "      <td>1070980</td>\n",
       "      <td>1070980</td>\n",
       "      <td>2141960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067000</th>\n",
       "      <td>1070979</td>\n",
       "      <td>1070978</td>\n",
       "      <td>2141957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691878</th>\n",
       "      <td>1070978</td>\n",
       "      <td>1070979</td>\n",
       "      <td>2141957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67128</th>\n",
       "      <td>1070977</td>\n",
       "      <td>1070977</td>\n",
       "      <td>2141954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770593</th>\n",
       "      <td>1070976</td>\n",
       "      <td>1070976</td>\n",
       "      <td>2141952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794104</th>\n",
       "      <td>1070975</td>\n",
       "      <td>1070975</td>\n",
       "      <td>2141950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          score1   score2    total\n",
       "632815   1070994  1070994  2141988\n",
       "565391   1070993  1070993  2141986\n",
       "1067359  1070992  1070992  2141984\n",
       "917941   1070991  1070991  2141982\n",
       "585117   1070990  1070990  2141980\n",
       "85885    1070989  1070989  2141978\n",
       "585438   1070988  1070988  2141976\n",
       "565397   1070987  1070987  2141974\n",
       "920627   1070986  1070986  2141972\n",
       "556608   1070985  1070985  2141970\n",
       "585119   1070984  1070984  2141968\n",
       "690832   1070983  1070983  2141966\n",
       "750815   1070982  1070982  2141964\n",
       "776305   1070981  1070981  2141962\n",
       "935157   1070980  1070980  2141960\n",
       "1067000  1070979  1070978  2141957\n",
       "691878   1070978  1070979  2141957\n",
       "67128    1070977  1070977  2141954\n",
       "770593   1070976  1070976  2141952\n",
       "794104   1070975  1070975  2141950"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.sort_values(by='total',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.to_csv('score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RECORD                  632816\n",
       "BBLE                4018420001\n",
       "B                            4\n",
       "BLOCK                     1842\n",
       "LOT                          1\n",
       "EASEMENT                   NaN\n",
       "OWNER       864163 REALTY, LLC\n",
       "BLDGCL                      D9\n",
       "TAXCLASS                     2\n",
       "LTFRONT                    157\n",
       "LTDEPTH                     95\n",
       "EXT                        NaN\n",
       "STORIES                      1\n",
       "FULLVAL               2.93e+06\n",
       "AVLAND              1.3185e+06\n",
       "AVTOT               1.3185e+06\n",
       "EXLAND                       0\n",
       "EXTOT                        0\n",
       "EXCD1                      NaN\n",
       "STADDR          86-55 BROADWAY\n",
       "ZIP                      11373\n",
       "EXMPTCL                    NaN\n",
       "BLDFRONT                     1\n",
       "BLDDEPTH                     1\n",
       "AVLAND2             1.2012e+06\n",
       "AVTOT2              1.2012e+06\n",
       "EXLAND2                    NaN\n",
       "EXTOT2                     NaN\n",
       "EXCD2                      NaN\n",
       "PERIOD                   FINAL\n",
       "YEAR                   2010/11\n",
       "VALTYPE                  AC-TR\n",
       "ZT                      113732\n",
       "Name: 632815, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.iloc[632815]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
